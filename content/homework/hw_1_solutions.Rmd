---
title: "Homework 1: Solutions"
date: "Due: Thursday 1/30/20 by 8:30am"
output: pdf_document
---

\color{blue}

Rubric: 

* 1 point for 1. if "I have installed `R`" was printed/written somewhere on the homework.
* Maximum of 3 points for 2., determined as follows:
   - 0 points for no solutions whatsoever or `R` output only;
   - 1 point for an honest effort but very few correct answers or `R` output only plus a figure;
   - 2 points for mostly correct answers but at least one substantial issue;
   - 3 points for nearly/exactly correct.
* Maximum of 2 points each for 3. and 4., determined as follows:
   - 0 points for no solutions whatsoever or `R` output only;
   - 1 point for an honest effort but at least one substantial issue;
   - 2 points for nearly/exactly correct.
    
\color{black}

2.  

(a) Obtain a 90 percent confidence interval for $\mu$ when $n = 424$, $\bar{Y} = 6.09$, and $s = 2.78$. 

\color{blue}
```{r}
n <- 424
y.bar <- 6.09
s <- 2.78

alpha <- 0.1


int <- y.bar + qt(c(alpha/2, 1 - alpha/2), 
                   df = n - 1)*s/sqrt(n)
```
We obtain a 95 percent confidence interval of (`r round(int[1], 2)`, `r round(int[2], 2)`).
\color{black}

(b) Simulate $1,000$ draws from the sampling distribution of $\bar{Y}$. Plot a histogram of $\bar{Y}$ on the density scale. Add vertical lines at $\bar{Y}$ and the upper and lower bounds of the interval derived in (a), and overlay the density of the sampling distribution of $\bar{Y}$ on the histogram.

\color{blue}
```{r, fig.align = 'center'}
sims <- rnorm(1000, mean = y.bar, sd = s/sqrt(n))
hist(sims, freq = FALSE,
     xlab = expression(bar(Y)),
     main = expression(paste("Histogram of the Sampling Distribution of ", 
                             bar(Y), sep = "")),
     ylim = c(0, 3))
vals <- seq(5, 7, length.out = 500)
lines(vals, dnorm(vals, mean = y.bar, sd = s/sqrt(n)),
      col = "blue")
abline(v = y.bar, col = "red")
abline(v = int, col = "red", lty = 2)
legend("topleft",
       col = c("blue", "red", "red"),
       lty = c(1, 1, 2),
       legend = c(expression(paste("Sampling Density of ", 
                                   bar(Y), sep = "")), 
                  expression(bar(Y)), 
                  expression(paste("2.5 and 97.5 Percent Quantiles of ", 
                                   bar(Y), sep = ""))),
       cex = 0.5, bg = "white")
```
\color{black}

3. Choose between the alternatives $H_0: \mu \geq 5$ and $H_a:\mu < 5$, where $\alpha$ is to be controlled at $0.03$ and $n = 84$, $\bar{Y} = 5.08$, and $s = 9.51$. Justify your answer with reference to the value of the test statistic, the decision rule, and the $p$-value.

\color{blue}
```{r}
alpha <- 0.03

n <- 84
y.bar <- 5.08
s <- 9.51

t.star <- (y.bar - 5)/(s/sqrt(n))
int <- qt(alpha, 
          df = n - 1)
pval <- pt(t.star, df = n - 1)
```

We fail to reject the null hypothesis at level $\alpha = 0.03$, because the test statistic is equal to `r round(t.star, 2)`, which is inside of the acceptance region (`r round(int, 2)`, $\infty$), and the p-value, which is `r round(pval, 2)` is much higher than $\alpha = 0.03$.

\color{black}


4. Choose between the alternatives $H_0: \mu = -10$ and $H_a: \mu \neq -10$ when $\alpha$ is to be controlled at $0.15$ and $n = 13$, $\bar{Y} = -6.81$, and $s = 1.55$. Justify your answer with reference to the value of the test statistic, the decision rule, and the $p$-value.

\color{blue}
```{r}
alpha <- 0.15

n <- 13
y.bar <- -6.81
s <- 1.55

t.star <- (y.bar - 10)/(s/sqrt(n))
int <- qt(c(alpha/2, 1 - alpha/2), 
          df = n - 1)
pval <- 2*pt(abs(t.star), df = n - 1, lower.tail = FALSE)
```

We reject the null hypothesis at level $\alpha = 0.15$, because the test statistic is equal to `r round(t.star, 2)`, which is outside of the acceptance region (`r round(int[1], 2)`, `r round(int[2], 2)`), and the p-value, which is $5.046509\times10^{-14}$ is much lower than $\alpha = 0.15$.

\color{black}

5. (In class, not to be submitted) 
(a) Obtain a 95 percent confidence interval for $\mu_1 - \mu_2$ when $n_1 = 49$, $\bar{Y} = 1.1$, $\sum \left(Y_i - \bar{Y}\right)^2 = 96.04$, $n_2 = 34$, $\bar{Z} = 3.37$, and $\sum \left(Z_i - \bar{Z}\right)^2 = 22.78$. 

\color{blue}
```{r}
n1 <- 49
y.bar <- 1.1
yiybarsq <- 94.04
n2 <- 34
z.bar <- 3.37
zizbarsq <- 22.78

alpha <- 0.05

ssq <- (yiybarsq + zizbarsq)/(n1 + n2 - 2)

int <- y.bar - z.bar + qt(c(alpha/2, 1 - alpha/2), 
                   df = n1 + n2 - 2)*sqrt(ssq/n1 + ssq/n2)
```
We obtain a 95 percent confidence interval of (`r round(int[1], 2)`, `r round(int[2], 2)`).
\color{black}

(b) Choose between the alternatives $H_0: \mu_1 = \mu_2$ and $H_a: \mu_1 \neq \mu_2$ when $\alpha$ is to be controlled at $0.01$. Justify your answer with reference to the value of the test statistic, the decision rule, and the $p$-value.

\color{blue}
```{r}
alpha <- 0.01

t.star <- (y.bar - z.bar)/(sqrt(ssq/n1 + ssq/n2))
int <- qt(c(alpha/2, 1 - alpha/2), 
          df = n1 + n2 - 2)
pval <- 2*pt(abs(t.star), df = n1 + n2 - 2, lower.tail = FALSE)
```

We reject the null hypothesis at level $\alpha = 0.01$, because the test statistic is equal to `r round(t.star, 2)`, which is outside of the acceptance region (`r round(int[1], 2)`, `r round(int[2], 2)`), and the p-value, which is $8.934652\times10^{-13}$ is much lower than $\alpha = 0.01$.
\color{black}


6. (In class, not to be submitted) 
(a) Obtain a 85 percent confidence interval for $\sigma^2$ when $n = 424$, $\bar{Y} = 6.09$, and $s = 2.78$. 
\color{blue}
```{r}
n <- 424
y.bar <- 6.09
s <- 2.78

alpha <- 0.15

int <- (n - 1)*s^2/qchisq(c(1 - alpha/2, alpha/2), n - 1)
```
We obtain a 85 percent confidence interval of (`r round(int[1], 2)`, `r round(int[2], 2)`).
\color{black}

```{r, echo = FALSE, eval = TRUE, fig.align = 'center'}
set.seed(1)
n <- 424; mean <- 6.09; sd <- 2.78
y <- rgamma(n, shape = 2, rate = 1/4)
y <- (y - mean(y))/sd(y)
y <- sd*y + mean
hist(y, xlab = "Y", freq = FALSE, main = "Histogram of Y")
```
(b) Suppose a peer who had access to the raw data showed you the above histogram of the values $Y_1, \dots, Y_n$. In at most one sentence, explain how this would affect your conclusions in (a).

\color{blue}
I would be less confident in my conclusions in (a), because confidence intervals for variances are sensitive to violations of normality of the data.
\color{black}

7. (In class, not to be submitted)  
(a) Obtain a 99 percent confidence interval for $\sigma_1^2/\sigma^2_2$ using the data from 5. 

\color{blue}
```{r}
n1 <- 49
y.bar <- 1.1
yiybarsq <- 94.04
n2 <- 34
z.bar <- 3.37
zizbarsq <- 22.78

alpha <- 0.01

ssq1 <- (yiybarsq)/(n1 - 1)
ssq2 <- (zizbarsq)/(n2 - 1)

int <- ssq1/(ssq2)/qf(c(1 - alpha/2, alpha/2), n1 - 1, n2 - 1)
```

We obtain a 99 percent confidence interval of (`r round(int[1], 2)`, `r round(int[2], 2)`).

\color{black}

(b) Choose between the alternatives $H_0: \sigma^2_1 = \sigma^2_2$ and $H_a: \sigma^2_1 \neq \sigma^2_2$ when $\alpha$ is to be controlled at $0.2$. Justify your answer with reference to the value of the test statistic and the decision rule.

\color{blue}
```{r}
alpha <- 0.2
t.star <- ssq1/(ssq2)
int <- qf(c(alpha/2, 1 - alpha/2), n1 - 1, n2 - 1)
```

We reject the null hypothesis at level $\alpha = 0.2$, because the test statistic is equal to `r round(t.star, 2)`, which is outside of the acceptance region (`r round(int[1], 2)`, `r round(int[2], 2)`).

\color{black}
